<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Remote Sensing-Based Mangrove Classification | Shubham Apat</title>
<meta name=keywords content="Remote Sensing,Machine Learning,Google Earth Engine,Random Forest"><meta name=description content="Developed a mangrove classification model for India using Sentinel-2A multispectral imagery and Random Forest classifier with 99.03% accuracy."><meta name=author content><link rel=canonical href=https://shubhamapat.github.io/projects/remote-sensing-mangrove-classification/><link crossorigin=anonymous href=/assets/css/stylesheet.5e650fcd2a1a270f991667f42593d548f47b391d604c83a6bdf0570f9f968095.css integrity="sha256-XmUPzSoaJw+ZFmf0JZPVSPR7OR1gTIOmvfBXD5+WgJU=" rel="preload stylesheet" as=style><link rel=icon href=https://shubhamapat.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shubhamapat.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shubhamapat.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://shubhamapat.github.io/apple-touch-icon.png><link rel=mask-icon href=https://shubhamapat.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://shubhamapat.github.io/projects/remote-sensing-mangrove-classification/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://shubhamapat.github.io/projects/remote-sensing-mangrove-classification/"><meta property="og:site_name" content="Shubham Apat"><meta property="og:title" content="Remote Sensing-Based Mangrove Classification"><meta property="og:description" content="Developed a mangrove classification model for India using Sentinel-2A multispectral imagery and Random Forest classifier with 99.03% accuracy."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2024-02-20T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-20T00:00:00+00:00"><meta property="article:tag" content="Remote Sensing"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Google Earth Engine"><meta property="article:tag" content="Random Forest"><meta property="og:image" content="https://shubhamapat.github.io/images/mangrove_outcome.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shubhamapat.github.io/images/mangrove_outcome.png"><meta name=twitter:title content="Remote Sensing-Based Mangrove Classification"><meta name=twitter:description content="Developed a mangrove classification model for India using Sentinel-2A multispectral imagery and Random Forest classifier with 99.03% accuracy."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://shubhamapat.github.io/projects/"},{"@type":"ListItem","position":2,"name":"Remote Sensing-Based Mangrove Classification","item":"https://shubhamapat.github.io/projects/remote-sensing-mangrove-classification/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Remote Sensing-Based Mangrove Classification","name":"Remote Sensing-Based Mangrove Classification","description":"Developed a mangrove classification model for India using Sentinel-2A multispectral imagery and Random Forest classifier with 99.03% accuracy.","keywords":["Remote Sensing","Machine Learning","Google Earth Engine","Random Forest"],"articleBody":"Overview Final semester project focused on developing a high-accuracy land cover classification system for mangrove ecosystems using satellite imagery and cloud-based geospatial platforms. The motivation behind this project was a research about mangroves that I was part of, where I learned to fly a drone over mangrove plantations for their monitoring and plantation.\nMangroves serve as vital coastal ecosystems, but their spatial distribution is often poorly mapped due to:\nPersistent cloud cover Limited accessibility to remote areas Inconsistent data quality The core objective is to develop a geospatial classification model capable of differentiating mangrove and non-mangrove classes using high-resolution satellite imagery. The focus is limited to the Indian subcontinent, where coastal zones are vulnerable to ecological degradation. The classification model is designed to be scalable, cloud-based, and capable of handling spatially distributed data.\nTo manually label and validate training samples using Global Mangrove Watch data Over 570 points were manually marked for each class (mangrove = 1, non-mangrove = 0). The labeling process was guided by GMW overlays and satellite base maps. Non-mangrove classes included forests, rivers, wastelands, mudflats, and urban backgrounds to ensure the classifier learned meaningful feature distinctions.\nTo compute vegetation indices and spectral bands for model input features The following indices and bands were used to improve model learning: -NDVI = (B8 - B4) / (B8 + B4) – to highlight vegetation density -NDWI = (B3 - B8) / (B3 + B8) – to separate water features -MNDWI = (B3 - B11) / (B3 + B11) – to enhance mudflat and wetland detection -Raw bands: B2 (Blue), B3 (Green), B4 (Red), B8 (NIR), B11 (SWIR)\nTo export the classification result as tile overlays for deployment Since GEE restricts model API deployment, the final classification image was exported as a map tile overlay using ee.Image.getMapId(), which allows integration with custom web applications.\nTo build an interactive click-to-classify frontend using Streamlit and Folium A responsive web application was created using Streamlit with embedded Folium maps. Key functionalities include: -Interactive satellite and terrain map views -Real-time click-to-classify feature using EE classification values -Visualization of mangrove (green) and non-mangrove (red) areas -Area estimation using pixel-wise aggregation of classified data\nStudy Area and Dataset Selection\nThe classification was geographically focused on the coastal regions of India, encompassing known mangrove ecosystems such as:\nSundarbans Gulf of Khambhat Gulf of Mannar Pichavaram Andaman \u0026 Nicobar Islands These areas were selected based on their ecological significance and confirmed mangrove presence using Global Mangrove Watch (GMW) overlays. The primary dataset used was Sentinel-2A Level-2A Surface Reflectance imagery.\nFor Data Sampling, a total of ˜570 points per class were manually marked.\nMangrove (class = 1): Points placed over dense mangrove patches, verified with GMW overlays and true-color images.\nNon-mangrove (class = 0): Points included:\nOpen water Urban areas Forest Wetlands Barren land Points were stored using custom Google Earth Engine scripts along with spatial metadata.\nEach point was enriched with the following features: Spectral Bands\nB2 (Blue, 10m) B3 (Green, 10m) B4 (Red, 10m) B8 (Near Infrared, 10m) B11 (Short Wave Infrared, 20m, resampled) Vegetation Indices\nNDVI = B8−B4/B8+B4 (indicates chlorophyll and biomass) NDWI = B3−B8/B3+B8 (highlights water bodies) This resulted in a 7-dimensional feature vector for each point: [B2, B3, B4, B8, B11, NDVI, NDWI].\nModel Training\nA Random Forest classifier was trained using the smileRandomForest module in GEE.\nFigure 3.4.1: Screenshot of the GEE script used for training the Random Forest classifier and exporting results. The console output on the right summarizes training-validation split, dataset balance, and feature selection used for classification. Train-test split: 70% training 30% testing Advantages of RF: Resistant to overfitting Handles non-linear relationships Offers feature importance analysis The model achieved an accuracy of 99.03%, validated using test points near the Mumbai coastline. Model Deployment\nDeployed using Streamlit, Google Earth Engine (GEE), and Folium for interactive mapping Initialized using GEE Python API, Tile layered generated with getMapId( ).\nI added Click \u0026 Classify functionality allows user to click a point on map and it captures Latitude and Longitude, how does it work? so Lats \u0026 Longs are converted to GEE point and Classification value (0 or 1) gets fetched using reduceRegion( ).\nOverall Architecture\nOutcome\nThe strong outcome validates the effectiveness of the supervised learning approach, the geo-point sampling strategy, and the value of vegetation indices like NDVI and NDWI in distinguishing mangroves from surrounding land covers.\n(a) Global Mangrove Watch Reference (b) Manually Labeled GeoPoints (c) Final Classified Overlay Figure 4.1.2: Comparison of classification process: (a) Reference from Global Mangrove Watch, (b) manually annotated geo-points used for training the classifier, and (c) final classification result overlaid as tile using the trained model.","wordCount":"771","inLanguage":"en","image":"https://shubhamapat.github.io/images/mangrove_outcome.png","datePublished":"2024-02-20T00:00:00Z","dateModified":"2024-02-20T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://shubhamapat.github.io/projects/remote-sensing-mangrove-classification/"},"publisher":{"@type":"Organization","name":"Shubham Apat","logo":{"@type":"ImageObject","url":"https://shubhamapat.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://shubhamapat.github.io/ accesskey=h title="Shubham Apat (Alt + H)">Shubham Apat</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shubhamapat.github.io/post/ title=Posts><span>Posts</span></a></li><li><a href=https://shubhamapat.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://shubhamapat.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://github.com/shubhamapat7 title=GitHub><span>GitHub</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Remote Sensing-Based Mangrove Classification</h1><div class=post-description>Developed a mangrove classification model for India using Sentinel-2A multispectral imagery and Random Forest classifier with 99.03% accuracy.</div><div class=post-meta><span title='2024-02-20 00:00:00 +0000 UTC'>February 20, 2024</span>&nbsp;·&nbsp;<span>4 min</span></div></header><figure class=entry-cover><img loading=eager src=https://shubhamapat.github.io/images/mangrove_outcome.png alt></figure><div class=post-content><h2 id=overview>Overview<a hidden class=anchor aria-hidden=true href=#overview>#</a></h2><img src=/images/mangrove_plantation.jpg><p>Final semester project focused on developing a high-accuracy land cover classification system for mangrove ecosystems using satellite imagery and cloud-based geospatial platforms. The motivation behind this project was a research about mangroves that I was part of, where I learned to fly a drone over mangrove plantations for their monitoring and plantation.</p><p>Mangroves serve as vital coastal ecosystems, but their spatial distribution is often poorly mapped due to:</p><ul><li>Persistent cloud cover</li><li>Limited accessibility to remote areas</li><li>Inconsistent data quality</li></ul><p>The core objective is to develop a geospatial classification model capable of differentiating
mangrove and non-mangrove classes using high-resolution satellite imagery. The focus
is limited to the Indian subcontinent, where coastal zones are vulnerable to ecological
degradation. The classification model is designed to be scalable, cloud-based, and capable
of handling spatially distributed data.</p><p>To manually label and validate training samples using Global Mangrove Watch data Over
570 points were manually marked for each class (mangrove = 1, non-mangrove = 0). The
labeling process was guided by GMW overlays and satellite base maps. Non-mangrove
classes included forests, rivers, wastelands, mudflats, and urban backgrounds to ensure the
classifier learned meaningful feature distinctions.</p><p>To compute vegetation indices and spectral bands for model input features
The following indices and bands were used to improve model learning:
-NDVI = (B8 - B4) / (B8 + B4) – to highlight vegetation density
-NDWI = (B3 - B8) / (B3 + B8) – to separate water features
-MNDWI = (B3 - B11) / (B3 + B11) – to enhance mudflat and wetland detection
-Raw bands: B2 (Blue), B3 (Green), B4 (Red), B8 (NIR), B11 (SWIR)</p><p>To export the classification result as tile overlays for deployment Since GEE restricts
model API deployment, the final classification image was exported as a map tile overlay
using ee.Image.getMapId(), which allows integration with custom web applications.</p><p>To build an interactive click-to-classify frontend using Streamlit and Folium A responsive web application was created using Streamlit with embedded Folium maps. Key
functionalities include:
-Interactive satellite and terrain map views
-Real-time click-to-classify feature using EE classification values
-Visualization of mangrove (green) and non-mangrove (red) areas
-Area estimation using pixel-wise aggregation of classified data</p><p><strong>Study Area and Dataset Selection</strong></p><p>The classification was geographically focused on the coastal regions of India, encompassing
known mangrove ecosystems such as:</p><ul><li>Sundarbans</li><li>Gulf of Khambhat</li><li>Gulf of Mannar</li><li>Pichavaram</li><li>Andaman & Nicobar Islands</li></ul><p>These areas were selected based on their ecological significance and confirmed mangrove
presence using Global Mangrove Watch (GMW) overlays.
The primary dataset used was Sentinel-2A Level-2A Surface Reflectance imagery.</p><img src=/images/mangrove_data_sampling.png><p>For Data Sampling, a total of ˜570 points per class were manually marked.</p><blockquote><p>Mangrove (class = 1): Points placed over dense mangrove patches, verified with
GMW overlays and true-color images.</p></blockquote><blockquote><p>Non-mangrove (class = 0): Points included:</p></blockquote><ul><li>Open water</li><li>Urban areas</li><li>Forest</li><li>Wetlands</li><li>Barren land</li></ul><blockquote><p>Points were stored using custom Google Earth Engine scripts along with spatial
metadata.</p></blockquote><p>Each point was enriched with the following features:
Spectral Bands</p><ul><li>B2 (Blue, 10m)</li><li>B3 (Green, 10m)</li><li>B4 (Red, 10m)</li><li>B8 (Near Infrared, 10m)</li><li>B11 (Short Wave Infrared, 20m, resampled)</li></ul><p>Vegetation Indices</p><ul><li>NDVI = B8−B4/B8+B4 (indicates chlorophyll and biomass)</li><li>NDWI = B3−B8/B3+B8 (highlights water bodies)</li></ul><p>This resulted in a 7-dimensional feature vector for each point: [B2, B3, B4, B8, B11,
NDVI, NDWI].</p><p><strong>Model Training</strong></p><p>A Random Forest classifier was trained using the smileRandomForest module in GEE.</p><img src=/images/gee-training.png>
<img src=/images/gee.png>
Figure 3.4.1: Screenshot of the GEE script used for training the Random Forest classifier
and exporting results. The console output on the right summarizes training-validation
split, dataset balance, and feature selection used for classification.<ul><li>Train-test split:<ul><li>70% training</li><li>30% testing</li></ul></li><li>Advantages of RF:<ul><li>Resistant to overfitting</li><li>Handles non-linear relationships</li><li>Offers feature importance analysis
The model achieved an accuracy of 99.03%, validated using test points near the Mumbai
coastline.</li></ul></li></ul><p><strong>Model Deployment</strong></p><p>Deployed using Streamlit, Google Earth Engine (GEE), and Folium for interactive mapping Initialized using GEE Python API, Tile layered generated with getMapId( ).</p><p>I added Click & Classify functionality allows user to click a point on map and it captures Latitude and Longitude, how does it work? so Lats & Longs are converted to GEE point and Classification value (0 or 1) gets fetched using reduceRegion( ).</p><left><img src=/images/mangrove_deployment1.png , width=1200>
</left><right><img src=/images/mangrove_deployment2.png , width=1200></right><p><strong>Overall Architecture</strong></p><img src=/images/mangrove_architecture.png><p><strong>Outcome</strong></p><p>The strong outcome validates the effectiveness of the supervised learning approach, the
geo-point sampling strategy, and the value of vegetation indices like NDVI and NDWI in
distinguishing mangroves from surrounding land covers.</p><img src=/images/mangrove_outcome.png>
(a) Global Mangrove Watch
Reference
(b) Manually Labeled GeoPoints
(c) Final Classified Overlay
Figure 4.1.2: Comparison of classification process:
(a) Reference from Global Mangrove
Watch,
(b) manually annotated geo-points used for training the classifier, and
(c) final
classification result overlaid as tile using the trained model.</div><footer class=post-footer><ul class=post-tags><li><a href=https://shubhamapat.github.io/tags/remote-sensing/>Remote Sensing</a></li><li><a href=https://shubhamapat.github.io/tags/machine-learning/>Machine Learning</a></li><li><a href=https://shubhamapat.github.io/tags/google-earth-engine/>Google Earth Engine</a></li><li><a href=https://shubhamapat.github.io/tags/random-forest/>Random Forest</a></li></ul><nav class=paginav><a class=prev href=https://shubhamapat.github.io/projects/bookmyshow-scraper/><span class=title>« Prev</span><br><span>BookMyShow Scraper</span>
</a><a class=next href=https://shubhamapat.github.io/projects/real-time-self-driving-car/><span class=title>Next »</span><br><span>Real-Time Self-Driving Car with Lane Detection</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://shubhamapat.github.io/>Shubham Apat</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>