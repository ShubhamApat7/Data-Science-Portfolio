<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Real-Time Self-Driving Car with Lane Detection | Shubham Apat</title>
<meta name=keywords content="Computer Vision,Raspberry Pi,OpenCV,IoT"><meta name=description content="Built a Raspberry Pi-based self-driving car capable of lane detection, obstacle avoidance, and path navigation using real-time image processing."><meta name=author content><link rel=canonical href=https://shubhamapat.github.io/projects/real-time-self-driving-car/><link crossorigin=anonymous href=/assets/css/stylesheet.5e650fcd2a1a270f991667f42593d548f47b391d604c83a6bdf0570f9f968095.css integrity="sha256-XmUPzSoaJw+ZFmf0JZPVSPR7OR1gTIOmvfBXD5+WgJU=" rel="preload stylesheet" as=style><link rel=icon href=https://shubhamapat.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shubhamapat.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shubhamapat.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://shubhamapat.github.io/apple-touch-icon.png><link rel=mask-icon href=https://shubhamapat.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://shubhamapat.github.io/projects/real-time-self-driving-car/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://shubhamapat.github.io/projects/real-time-self-driving-car/"><meta property="og:site_name" content="Shubham Apat"><meta property="og:title" content="Real-Time Self-Driving Car with Lane Detection"><meta property="og:description" content="Built a Raspberry Pi-based self-driving car capable of lane detection, obstacle avoidance, and path navigation using real-time image processing."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2024-01-15T00:00:00+00:00"><meta property="article:modified_time" content="2024-01-15T00:00:00+00:00"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Raspberry Pi"><meta property="article:tag" content="OpenCV"><meta property="article:tag" content="IoT"><meta property="og:image" content="https://shubhamapat.github.io/images/autonomous_car.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shubhamapat.github.io/images/autonomous_car.png"><meta name=twitter:title content="Real-Time Self-Driving Car with Lane Detection"><meta name=twitter:description content="Built a Raspberry Pi-based self-driving car capable of lane detection, obstacle avoidance, and path navigation using real-time image processing."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://shubhamapat.github.io/projects/"},{"@type":"ListItem","position":2,"name":"Real-Time Self-Driving Car with Lane Detection","item":"https://shubhamapat.github.io/projects/real-time-self-driving-car/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Real-Time Self-Driving Car with Lane Detection","name":"Real-Time Self-Driving Car with Lane Detection","description":"Built a Raspberry Pi-based self-driving car capable of lane detection, obstacle avoidance, and path navigation using real-time image processing.","keywords":["Computer Vision","Raspberry Pi","OpenCV","IoT"],"articleBody":"Developed an autonomous self-driving car using Raspberry Pi with advanced computer vision capabilities for lane detection and obstacle avoidance.\nTechnical Implementation Image Processing Pipeline Real-time image processing with OpenCV Perspective transformation for bird’s eye view Thresholding for lane detection Histogram-based lane tracking Hardware Integration Integrated multiple sensors: IR sensors for obstacle detection Ultrasonic sensors for distance measurement Photoresistors for ambient light detection Real-time control logic for: Steering adjustments Acceleration control Automatic braking An autonomous car with image processing employs a sophisticated network of sensors to navigate its surroundings intelligently. Central to this system is a camera that captures real-time images, providing the foundational visual input for the car. These images undergo intricate image processing, facilitated by advanced algorithms, to recognize crucial elements such as lane markings, traffic signs, and obstacles.\nComplementing the camera, infrared (IR) sensors enhance the car’s perceptual capabilities, especially in low-light conditions, by detecting obstacles through emitted and reflected infrared light. Ultrasonic sensors contribute to proximity sensing, utilizing sound waves to measure distances to nearby objects and aiding the car in navigation through confined spaces. Photodiode sensors play a pivotal role in maintaining the car’s trajectory by detecting variations in light intensity and ensuring alignment with lane markings.\nThe image processing model, running on a dedicated processing unit, synthesizes data from these sensors to generate a dynamic understanding of the environment. A sophisticated control system integrates this information, translating it into precise steering, acceleration, and braking commands. This amalgamation of image processing and sensor data enables the autonomous car to navigate predefined paths, respond to traffic signs, and adapt to its surroundings, marking a significant advancement in the realization of intelligent and safe autonomous transportation.\nHow the Image Processing was implemented for lane detection:\nCapturing Frames from the Camera\nThe camera is initialized with specific settings — frame width, height, brightness, etc. Each frame is captured and converted from BGR to RGB (since OpenCV uses BGR by default).\nvoid Capture() { Camera.grab(); Camera.retrieve(frame); cvtColor(frame, frame, COLOR_BGR2RGB); } Perspective Transformation\nWe convert the front-facing view into a bird’s-eye (top-down) view using four defined source and destination points.\nThis simplifies the lane detection process since lane lines appear straight in this view.\nMatrix = getPerspectiveTransform(Source, Destination); warpPerspective(frame, framePers, Matrix, Size(400,240)); Lane Line Isolation (Thresholding + Edges)\nThe system applies grayscale conversion, thresholding, and Canny edge detection to isolate lane markings.\ncvtColor(framePers, frameGray, COLOR_RGB2GRAY); inRange(frameGray, 200, 255, frameThresh); Canny(frameGray, frameEdge, 900, 900, 3, false); add(frameThresh, frameEdge, frameFinal); Histogram Analysis\nTo find lane positions, the code scans the bottom portion of the image column by column and computes a histogram of white pixel intensities.\nfor(int i=0; i\u003c400; i++) { ROILane = frameFinalDuplicate(Rect(i,140,1,100)); divide(255, ROILane, ROILane); histrogramLane.push_back((int)(sum(ROILane)[0])); } Detecting Lanes and Center Offset\nThe program identifies the maximum peaks on both sides of the histogram — these correspond to lane positions.\nLeftLanePos = distance(histrogramLane.begin(), max_element(histrogramLane.begin(), histrogramLane.begin() + 150)); RightLanePos = distance(histrogramLane.begin() +250, max_element(histrogramLane.begin() +250, histrogramLane.end())); Then it calculates the lane center and compares it to the frame center (188 pixels):Then it calculates the lane center and compares it to the frame center (188 pixels):\nlaneCenter = (RightLanePos - LeftLanePos)/2 + LeftLanePos; Result = laneCenter - frameCenter; Steering Decision via GPIO\nBased on the Result value, specific GPIO pins are activated to signal movement direction. Each pattern corresponds to a particular motion.\nif (Result == 0) { cout \u003c\u003c \"Forward\"; } else if (Result \u003e0 \u0026\u0026 Result \u003c10) { cout \u003c\u003c \"Right1\"; } else if (Result \u003e=10 \u0026\u0026 Result \u003c20) { cout \u003c\u003c \"Right2\"; } else if (Result \u003e20) { cout \u003c\u003c \"Right3\"; } else if (Result \u003c0 \u0026\u0026 Result \u003e-10) { cout \u003c\u003c \"Left1\"; } else if (Result \u003c=-10 \u0026\u0026 Result \u003e-20) { cout \u003c\u003c \"Left2\"; } else if (Result \u003c-20) { cout \u003c\u003c \"Left3\"; } Visualization and FPS\nThe system displays three live OpenCV windows:\nOriginal View (raw camera feed)\nPerspective View (bird’s-eye transformation)\nFinal View (processed lane lines)\nIt also calculates and prints real-time FPS to monitor performance.\nResults:\nDetects lanes in real-time at ~15–20 FPS on Raspberry Pi Outputs steering directions instantly Can be integrated with an RC car or motor driver for autonomous navigation\n","wordCount":"686","inLanguage":"en","image":"https://shubhamapat.github.io/images/autonomous_car.png","datePublished":"2024-01-15T00:00:00Z","dateModified":"2024-01-15T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://shubhamapat.github.io/projects/real-time-self-driving-car/"},"publisher":{"@type":"Organization","name":"Shubham Apat","logo":{"@type":"ImageObject","url":"https://shubhamapat.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://shubhamapat.github.io/ accesskey=h title="Shubham Apat (Alt + H)">Shubham Apat</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shubhamapat.github.io/post/ title=Posts><span>Posts</span></a></li><li><a href=https://shubhamapat.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://shubhamapat.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://github.com/shubhamapat7 title=GitHub><span>GitHub</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Real-Time Self-Driving Car with Lane Detection</h1><div class=post-description>Built a Raspberry Pi-based self-driving car capable of lane detection, obstacle avoidance, and path navigation using real-time image processing.</div><div class=post-meta><span title='2024-01-15 00:00:00 +0000 UTC'>January 15, 2024</span>&nbsp;·&nbsp;<span>4 min</span></div></header><figure class=entry-cover><img loading=eager src=https://shubhamapat.github.io/images/autonomous_car.png alt></figure><div class=post-content><p>Developed an autonomous self-driving car using Raspberry Pi with advanced computer vision capabilities for lane detection and obstacle avoidance.</p><h2 id=technical-implementation>Technical Implementation<a hidden class=anchor aria-hidden=true href=#technical-implementation>#</a></h2><h3 id=image-processing-pipeline>Image Processing Pipeline<a hidden class=anchor aria-hidden=true href=#image-processing-pipeline>#</a></h3><ul><li><strong>Real-time image processing</strong> with OpenCV</li><li>Perspective transformation for bird&rsquo;s eye view</li><li>Thresholding for lane detection</li><li>Histogram-based lane tracking</li></ul><h3 id=hardware-integration>Hardware Integration<a hidden class=anchor aria-hidden=true href=#hardware-integration>#</a></h3><ul><li>Integrated multiple sensors:<ul><li>IR sensors for obstacle detection</li><li>Ultrasonic sensors for distance measurement</li><li>Photoresistors for ambient light detection</li></ul></li><li>Real-time control logic for:<ul><li>Steering adjustments</li><li>Acceleration control</li><li>Automatic braking</li></ul></li></ul><p>An autonomous car with image processing employs a sophisticated network of sensors to navigate its surroundings intelligently. Central to this system is a camera that captures real-time images, providing the foundational visual input for the car. These images undergo intricate image processing, facilitated by advanced algorithms, to recognize crucial elements such as lane markings, traffic signs, and obstacles.</p><p>Complementing the camera, infrared (IR) sensors enhance the car&rsquo;s perceptual capabilities, especially in low-light conditions, by detecting obstacles through emitted and reflected infrared light.
Ultrasonic sensors contribute to proximity sensing, utilizing sound waves to measure distances to nearby objects and aiding the car in navigation through confined spaces.
Photodiode sensors play a pivotal role in maintaining the car&rsquo;s trajectory by detecting variations in light intensity and ensuring alignment with lane markings.</p><p>The image processing model, running on a dedicated processing unit, synthesizes data from these sensors to generate a dynamic understanding of the environment. A sophisticated control system integrates this information, translating it into precise steering, acceleration, and braking commands. This amalgamation of image processing and sensor data enables the autonomous car to navigate predefined paths, respond to traffic signs, and adapt to its surroundings, marking a significant advancement in the realization of intelligent and safe autonomous transportation.</p><img src=/images/autonomous_car.png><p>How the Image Processing was implemented for lane detection:</p><p>Capturing Frames from the Camera</p><p>The camera is initialized with specific settings — frame width, height, brightness, etc.
Each frame is captured and converted from BGR to RGB (since OpenCV uses BGR by default).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>void Capture()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    Camera<span style=color:#f92672>.</span>grab();
</span></span><span style=display:flex><span>    Camera<span style=color:#f92672>.</span>retrieve(frame);
</span></span><span style=display:flex><span>    cvtColor(frame, frame, COLOR_BGR2RGB);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Perspective Transformation</p><p>We convert the front-facing view into a bird’s-eye (top-down) view using four defined source and destination points.</p><p>This simplifies the lane detection process since lane lines appear straight in this view.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>Matrix <span style=color:#f92672>=</span> getPerspectiveTransform(Source, Destination);
</span></span><span style=display:flex><span>warpPerspective(frame, framePers, Matrix, Size(<span style=color:#ae81ff>400</span>,<span style=color:#ae81ff>240</span>));
</span></span></code></pre></div><p>Lane Line Isolation (Thresholding + Edges)</p><p>The system applies grayscale conversion, thresholding, and Canny edge detection to isolate lane markings.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>cvtColor(framePers, frameGray, COLOR_RGB2GRAY);
</span></span><span style=display:flex><span>inRange(frameGray, <span style=color:#ae81ff>200</span>, <span style=color:#ae81ff>255</span>, frameThresh);
</span></span><span style=display:flex><span>Canny(frameGray, frameEdge, <span style=color:#ae81ff>900</span>, <span style=color:#ae81ff>900</span>, <span style=color:#ae81ff>3</span>, false);
</span></span><span style=display:flex><span>add(frameThresh, frameEdge, frameFinal);
</span></span></code></pre></div><p>Histogram Analysis</p><p>To find lane positions, the code scans the bottom portion of the image column by column and computes a histogram of white pixel intensities.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>for</span>(int i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span><span style=color:#ae81ff>400</span>; i<span style=color:#f92672>++</span>)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    ROILane <span style=color:#f92672>=</span> frameFinalDuplicate(Rect(i,<span style=color:#ae81ff>140</span>,<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>100</span>));
</span></span><span style=display:flex><span>    divide(<span style=color:#ae81ff>255</span>, ROILane, ROILane);
</span></span><span style=display:flex><span>    histrogramLane<span style=color:#f92672>.</span>push_back((int)(sum(ROILane)[<span style=color:#ae81ff>0</span>]));
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Detecting Lanes and Center Offset</p><p>The program identifies the maximum peaks on both sides of the histogram — these correspond to lane positions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>LeftLanePos <span style=color:#f92672>=</span> distance(histrogramLane<span style=color:#f92672>.</span>begin(),
</span></span><span style=display:flex><span>                       max_element(histrogramLane<span style=color:#f92672>.</span>begin(), histrogramLane<span style=color:#f92672>.</span>begin() <span style=color:#f92672>+</span> <span style=color:#ae81ff>150</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RightLanePos <span style=color:#f92672>=</span> distance(histrogramLane<span style=color:#f92672>.</span>begin() <span style=color:#f92672>+</span><span style=color:#ae81ff>250</span>,
</span></span><span style=display:flex><span>                        max_element(histrogramLane<span style=color:#f92672>.</span>begin() <span style=color:#f92672>+</span><span style=color:#ae81ff>250</span>, histrogramLane<span style=color:#f92672>.</span>end()));
</span></span></code></pre></div><p>Then it calculates the lane center and compares it to the frame center (188 pixels):Then it calculates the lane center and compares it to the frame center (188 pixels):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>laneCenter <span style=color:#f92672>=</span> (RightLanePos <span style=color:#f92672>-</span> LeftLanePos)<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> LeftLanePos;
</span></span><span style=display:flex><span>Result <span style=color:#f92672>=</span> laneCenter <span style=color:#f92672>-</span> frameCenter;
</span></span></code></pre></div><p>Steering Decision via GPIO</p><p>Based on the Result value, specific GPIO pins are activated to signal movement direction.
Each pattern corresponds to a particular motion.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Forward&#34;</span>; }
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>&gt;</span><span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span> Result <span style=color:#f92672>&lt;</span><span style=color:#ae81ff>10</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Right1&#34;</span>; }
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>&gt;=</span><span style=color:#ae81ff>10</span> <span style=color:#f92672>&amp;&amp;</span> Result <span style=color:#f92672>&lt;</span><span style=color:#ae81ff>20</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Right2&#34;</span>; }
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>&gt;</span><span style=color:#ae81ff>20</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Right3&#34;</span>; }
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>&lt;</span><span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span> Result <span style=color:#f92672>&gt;-</span><span style=color:#ae81ff>10</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Left1&#34;</span>; }
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>&lt;=-</span><span style=color:#ae81ff>10</span> <span style=color:#f92672>&amp;&amp;</span> Result <span style=color:#f92672>&gt;-</span><span style=color:#ae81ff>20</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Left2&#34;</span>; }
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> (Result <span style=color:#f92672>&lt;-</span><span style=color:#ae81ff>20</span>) { cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Left3&#34;</span>; }
</span></span></code></pre></div><p>Visualization and FPS</p><p>The system displays three live OpenCV windows:</p><blockquote><p>Original View (raw camera feed)</p></blockquote><blockquote><p>Perspective View (bird’s-eye transformation)</p></blockquote><blockquote><p>Final View (processed lane lines)</p></blockquote><p>It also calculates and prints real-time FPS to monitor performance.</p><p><strong>Results</strong>:</p><blockquote><p>Detects lanes in real-time at ~15–20 FPS on Raspberry Pi
Outputs steering directions instantly
Can be integrated with an RC car or motor driver for autonomous navigation</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://shubhamapat.github.io/tags/computer-vision/>Computer Vision</a></li><li><a href=https://shubhamapat.github.io/tags/raspberry-pi/>Raspberry Pi</a></li><li><a href=https://shubhamapat.github.io/tags/opencv/>OpenCV</a></li><li><a href=https://shubhamapat.github.io/tags/iot/>IoT</a></li></ul><nav class=paginav><a class=prev href=https://shubhamapat.github.io/projects/remote-sensing-mangrove-classification/><span class=title>« Prev</span><br><span>Remote Sensing-Based Mangrove Classification</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://shubhamapat.github.io/>Shubham Apat</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>